{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82f45520-6a6d-49b2-9dfd-ea33231e7b39",
   "metadata": {},
   "source": [
    "# End-to-End RAG Tutorial Using Jira, PyAirbyte, Pinecone, and LangChain\n",
    "\n",
    "This notebook demonstrates an end-to-end Retrieval-Augmented Generation (RAG) pipeline. We will extract data from Jira using PyAirbyte, store it in a Pinecone vector store, and then use LangChain to perform RAG on the stored data. This workflow showcases how to integrate these tools to build a scalable RAG system.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Jira**:\n",
    "   - Follow the instructions in the [Jira Source Connector Documentation](https://docs.airbyte.com/integrations/sources/jira) to set up your jira airbyte source\n",
    "\n",
    "2. **Pinecone Account**:\n",
    "   - **Create a Pinecone Account**: Sign up for an account on the [Pinecone website](https://www.pinecone.io/).\n",
    "   - **Obtain Pinecone API Key**: Generate a new API key from your Pinecone project settings. For detailed instructions, refer to the [Pinecone documentation](https://docs.pinecone.io/docs/quickstart).\n",
    "\n",
    "3. **OpenAI API Key**:\n",
    "   - **Create an OpenAI Account**: Sign up for an account on [OpenAI](https://www.openai.com/).\n",
    "   - **Generate an API Key**: Go to the API section and generate a new API key. For detailed instructions, refer to the [OpenAI documentation](https://beta.openai.com/docs/quickstart).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e598e-10b5-4fd3-891f-e316cbc4a341",
   "metadata": {},
   "source": [
    "## Install PyAirbyte and other dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3954735e-6c45-4d15-b2a2-4fc705c935b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install airbyte openai langchain pinecone-client langchain-openai langchain-pinecone langchainhub "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f0ec02-f31c-44ff-ac7e-49af6f608c9e",
   "metadata": {},
   "source": [
    "# Setup Source Jira with PyAirbyte\n",
    "\n",
    "The provided code configures an Airbyte source to extract issues data from jira data\n",
    "\n",
    "To configure according to your requirements, you can refer to [this references](https://docs.airbyte.com/integrations/sources/jira#reference).\n",
    "\n",
    "Note: The credentials are retrieved securely using the get_secret() method. This will automatically locate a matching Google Colab secret or environment variable, ensuring they are not hard-coded into the notebook. Make sure to add your key to the Secrets section on the left.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936c79e8-2eff-4d4a-ae51-74d8f14c7005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import airbyte as ab\n",
    "import json\n",
    "\n",
    "projects = json.loads(ab.get_secret('projects_list'))\n",
    "\n",
    "source = ab.get_source(\n",
    "    \"source-jira\",\n",
    "    install_if_missing=True,\n",
    "    config={\n",
    "        \"api_token\": ab.get_secret('jira_api_token'),\n",
    "        \"domain\": ab.get_secret('jira_domain') ,\n",
    "        \"email\":  ab.get_secret('jira_email_id'),\n",
    "        \"start_date\": \"2021-01-01T00:00:00Z\", # optional field, can be ignored \n",
    "        \"projects\": projects\n",
    "        },\n",
    "\n",
    ")\n",
    "\n",
    "# Verify the config and creds by running `check`:\n",
    "source.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89205323-0676-4869-bcf6-fbbb31333a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source.select_streams(['issues']) # Select only issues stream\n",
    "read_result: ab.ReadResult = source.read()\n",
    "documents_list = []\n",
    "\n",
    "for key, value in read_result.items():\n",
    "    docs = value.to_documents()\n",
    "    for doc in docs:\n",
    "        documents_list.append(doc)\n",
    "\n",
    "print(str(documents_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c76d164-8894-41b6-aee6-a3de0a70aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store and display the issues stream in data frame\n",
    "issues_df = read_result[\"issues\"].to_pandas()\n",
    "display(issues_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770f07e7-9dd6-4bd3-b180-fc322eb1e209",
   "metadata": {},
   "source": [
    "## Use Langchain to build a RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8194e7ba-4aef-4fdf-afef-93a5dee0e36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.utils import filter_complex_metadata\n",
    "\n",
    "\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=50)\n",
    "chunked_docs = splitter.split_documents(documents_list)\n",
    "chunked_docs = filter_complex_metadata(chunked_docs)\n",
    "print(f\"Created {len(chunked_docs)} document chunks.\")\n",
    "\n",
    "for doc in chunked_docs:\n",
    "    for md in doc.metadata:\n",
    "        doc.metadata[md] = str(doc.metadata[md])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eeea04-f774-4a6b-840a-999aed9f80ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = ab.get_secret(\"OPENAI_API_KEY\")\n",
    "\n",
    "embeddings=OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac9b188-2972-42b4-a9bb-7d752b0eeaf3",
   "metadata": {},
   "source": [
    "## Setting up Pinecone\n",
    "\n",
    "Pinecone is a managed vector database service designed for storing, indexing, and querying high-dimensional vector data efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f11593-3ea2-4762-ad23-e21c87d44ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "os.environ['PINECONE_API_KEY'] = ab.get_secret(\"PINECONE_API_KEY\")\n",
    "\n",
    "index_name = \"airbytejiraindex\"\n",
    "\n",
    "pc = Pinecone()\n",
    "\n",
    "# Create pinecone index if not exists otherwise skip this step\n",
    "if not (pc.list_indexes()[0]['name'] == index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7efdc6-4363-4c3e-bd6e-86b955f2e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(index_name)\n",
    "\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bdb85f-be90-47b0-a778-9232c81427c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "pinecone = PineconeVectorStore.from_documents(\n",
    "    chunked_docs, embedding=embeddings, index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5d31fa-6f88-4755-9405-6f7c84495607",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb7f799-3558-49f4-8c20-2a45ac61c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retriever = pinecone.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = ab.get_secret(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(\"Langchain RAG pipeline set up successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3dd498-74a3-4868-8529-bdad7d949d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rag_chain.invoke(\"Summarize the issue of key IT-20\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b7761-c463-430d-8150-3e816897cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rag_chain.invoke(\"What is the source data about?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
